<!-- ## About me -->
I'm a first year master's student of Computational Neuroscience at University of Tübingen and a [Graduate Research Assistant](https://www.kyb.tuebingen.mpg.de/person/139231/711799){:target="_blank" rel="noopener"} at [Cognitive Neuroscience & Neurotechnology Lab](https://www.kyb.tuebingen.mpg.de/cognitive-neuroscience-neurotechnology){:target="_blank" rel="noopener"}, Max Planck Institute for Biological Cybernetics under [Dr Romy Lorenz](https://www.kyb.tuebingen.mpg.de/person/128303/711763){:target="_blank" rel="noopener"}. 

**“The cosmos is within us. We are made of star stuff. _We are a way for the universe to know itself._”** ― Carl Sagan

I'm interested in understanding the underlying first principles of intelligence (such as [FEP](https://www.nature.com/articles/nrn2787){:target="_blank" rel="noopener"}), focusing on unique behaviours and phenomena arising from/in human brains. Essentially, I want to understand what makes homo sapiens stand out from all other life forms in their ability to tame nature and their depth of creativity. Many life forms possess brains, and we share many of the same neural mechanisms; we may have much more in common than what is different. Yet, I'm interested in understanding that potent tiny difference in the underlying neural architecture and mechanisms of human brains. Those differences might exist at any scale, from molecular to proteins to channels to synapses to neurons, populations to regions to [networks](https://mitpress.mit.edu/9780262528986/networks-of-the-brain/){:target="_blank" rel="noopener"}, to some unknown emergent architecture. I wish to find and understand them. 

**"What I cannot build, I do not understand."** — Richard Feynman 

My interest in AI is only to test our extent of understanding of human intelligence. Current AI systems are energy-inefficient, and [neuromorphic computing](https://www.nature.com/articles/s41586-024-08253-8){:target="_blank" rel="noopener"} might hold some value in energy efficiency. Thus, I'm also interested in the [thermodynamics of computation](https://www.santafe.edu/research/projects/thermodynamics-computation){:target="_blank" rel="noopener"} in human brains. I'm trying to keep up with the [NeuroAI](https://www.nature.com/articles/s41467-023-37180-x){:target="_blank" rel="noopener"} space and [Active-Inference](https://arxiv.org/abs/2212.01354){:target="_blank" rel="noopener"} based methods.

Understanding systems lets one know when and why they fail and how to manipulate and improve them. A principled understanding of the brain and its interaction with the environment can help us fix failings at different scales, from neuronal ones such as Parkinson's to psychological ones such as depression to social ones such as [genocide](https://en.wikipedia.org/wiki/Gaza_genocide). The human brain is taking action at the centre of psychology, sociology, economics and politics. These complex emergent phenomenons deserve to be studied at their own scales. Still, I want to bridge the gaps across scales, starting from the brain at the bottom. This is why I'm fascinated with [complexity science](https://complexityexplained.github.io){:target="_blank" rel="noopener"} and deeply inspired by "[The Complex World](https://davidckrakauer.com/artifacts/2024the-complex-world-an-introduction-to-the-foundations-of-complexity-science){:target="_blank" rel="noopener"}" book by David C. Krakauer.

My interests are broad and ambitious. Thus, I'm trying to zero in on a few questions I want to pursue over the next few years as part of my master's thesis and a PhD. I wish to not limit myself to demarcations of fields and tools and be open to learning/researching everything and anything to satisfy my curiosities. Suggestions on research questions worth pursuing will be highly appreciated!




### Background
I completed my B.Tech. Computer Engineering at Jamia Millia Islamia University, New Delhi in June 2024. I was supervised by [Prof. Tanvir Ahmad](https://scholar.google.co.in/citations?user=y7YNRzoAAAAJ&hl=en){:target="_blank" rel="noopener"} on my Bachelor's thesis on ["Music Generation from Brain Scans"](/assets/docs/Major_Thesis_MusicBrain.pdf){:target="_blank" rel="noopener"} which was my first major exploration into a problem of neuroscience involving reconstructing the music listened by subjects purely from their fMRI scans. This project made me fell in love with neuroscience. 

As part of my Bachelors Minor Thesis, I explored GNNs, LLMs, and RAG techniques for the research competition of Multimodal Emotion-Cause Pair Extraction in Conversations, a [SemEval 2024](https://arxiv.org/abs/2403.04798){:target="_blank" rel="noopener"} Task. 

I've also worked as a researcher at the [HCTL Lab, TU Munich](https://www.edu.sot.tum.de/en/hctl/home/){:target="_blank" rel="noopener"} led by [Prof. Dr. Enkelejda Kasneci](https://scholar.google.com/citations?user=bZVkVvoAAAAJ){:target="_blank" rel="noopener"}. I was supervised by [Yao Rong](https://yaorong0921.github.io/homepage/){:target="_blank" rel="noopener"} on the topic of self-supervised learning for scanpaths. I was a full-time summer research intern at TUM in 2023  funded by  [DAAD-WISE Scholarship](https://www.daad.in/en/find-funding/scholarship-database/?type=a&q=&status=1&subject=F&onlydaad=1&detail_to_show=0&target=4&origin=4&pg=1&detail_to_show=50015295){:target="_blank" rel="noopener"}. Previously, I've been a summer research intern at IIIT Allahabad under [Prof. Anupam Agarwal](https://scholar.google.co.in/citations?user=mVXjhhgAAAAJ&hl=en){:target="_blank" rel="noopener"} where I worked on ASD diagnosis based on visual attention. I was mentored on my first research [paper](https://www.iosrjournals.org/iosr-jce/papers/Vol25-issue1/Ser-1/E2501013749.pdf){:target="_blank" rel="noopener"} on wild scene text localization in images by [Hitesh Hinduja](https://hitesh-hinduja.mystrikingly.com/){:target="_blank" rel="noopener"}. 

I've had the honor of leading my team sCUDA_Divers to the Grand Finales of [Smart India Hackathon](https://www.sih.gov.in/sih2023){:target="_blank" rel="noopener"} for consecutive years of 2022 and 2023. Our hackathon project on the Super-Resolution of Digital Elevation Models culminated in a research paper published in [IEEE IGARSS 2023](https://ieeexplore.ieee.org/abstract/document/10283196){:target="_blank" rel="noopener"}.


 
### Highlights
```01/02/2025``` &nbsp; [Began Research Assistantship at Romy's Lab!](https://www.kyb.tuebingen.mpg.de/person/139231/711799){:target="_blank" rel="noopener"} \
```01/10/2024``` &nbsp; [Began Master's in Computational Neuroscience at Tübingen!](https://www.neuroschool-tuebingen.de/master/comp-neurosci-neural-inf-process/){:target="_blank" rel="noopener"} \
```23/05/2024``` &nbsp; [Graduated with Honours in B.Tech. Computer Engineering!](./assets/docs/degree.pdf){:target="_blank" rel="noopener"} \
```19/03/2024``` &nbsp; [Paper on LLMs Accepted in SemEval 2024 Workshop!](https://arxiv.org/abs/2403.04798){:target="_blank" rel="noopener"} \
```06/03/2024``` &nbsp; [2nd Rank in Third Year of Computer Engineering!](./assets/docs/third-year-rank-list.pdf){:target="_blank" rel="noopener"} \
```31/01/2024``` &nbsp; [Team JMI Secured 4th Position at SemEval Task-3!](https://codalab.lisn.upsaclay.fr/competitions/16141#results){:target="_blank" rel="noopener"} \
    ```19/12/2023``` &nbsp; [Grand Finalist of SIH 2023 at KIT, Kolhapur!](./assets/docs/sih2023.pdf){:target="_blank" rel="noopener"} \
```01/08/2023``` &nbsp; [Completed Summer Research Internship at TU Munich!](./assets/docs/TUM.pdf){:target="_blank" rel="noopener"}\
```16/07/2023``` &nbsp; [Master GAN Paper Published in IGARSS 2023!](https://ieeexplore.ieee.org/abstract/document/10283196){:target="_blank" rel="noopener"} \
```10/04/2023``` &nbsp; [3rd Rank in Second Year of Computer Engineering!](./assets/docs/second-year-rank-list.pdf){:target="_blank" rel="noopener"} \
```17/02/2023``` &nbsp; [Text Localization Paper Published in IOSR Journal!](https://www.iosrjournals.org/iosr-jce/papers/Vol25-issue1/Ser-1/E2501013749.pdf){:target="_blank" rel="noopener"} \
```16/01/2023``` &nbsp; [Achieved DAAD-WISE Scholarship!](./assets/docs/DAAD-Scholarship.pdf){:target="_blank" rel="noopener"} \
```25/08/2022``` &nbsp; [Grand Finalist of SIH 2022 at GTU, Ahmedabad!](./assets/docs/sih2022.pdf){:target="_blank" rel="noopener"} \
```15/07/2022``` &nbsp; [Completed Summer Research Internship at IIIT Allahabad!](./assets/docs/IIITA-Cert.pdf){:target="_blank" rel="noopener"}

### Publications

***JMI at SemEval 2024 Task 3: Two-step approach for multimodal ECAC using in-context learning with GPT and instruction-tuned Llama models***  
Arefa, *M. A. Ansari*\*, C. Saxena, T. Ahmad \
ACL SemEval Workshop, 2024\
\[[PDF](https://aclanthology.org/2024.semeval-1.223.pdf){:target="_blank" rel="noopener"}\] \[[Code](https://github.com/CMOONCS/SemEval-2024_MultiModal_ECPE/tree/main){:target="_blank" rel="noopener"}\]

***Master GAN: Multiple Attention is all you Need: A Multiple Attention Guided Super Resolution Network for Dems***  
A. Mohammed, M. Kashif, M. H. Zama, *M. A. Ansari*\* and S. Ali \
IEEE IGARSS, 2023\
\[[PDF](https://ieeexplore.ieee.org/abstract/document/10283196){:target="_blank" rel="noopener"}\] \[[Code](https://github.com/sheikhazhanmohammed/MASTERGAN){:target="_blank" rel="noopener"}\]

***Revisiting TextFuseNet: Text Context Enhanced Attention Networks For Scene Text Localization***  
H. Hinduja, *M. A. Ansari*\* \
IOSR Journal of Computer Engineering, 2023\
\[[PDF](https://www.iosrjournals.org/iosr-jce/papers/Vol25-issue1/Ser-1/E2501013749.pdf){:target="_blank" rel="noopener"}\] \[[Code](https://github.com/m-abbas-ansari/AttentionText){:target="_blank" rel="noopener"}\]

### Projects
*In order of recency:*

**Music Generation from Brain Scans**  
*Bachelors Major Thesis, 2024*\
\[[Thesis](./assets/docs/Major_Thesis_MusicBrain.pdf){:target="_blank" rel="noopener"}\] 
\[[Slides](https://docs.google.com/presentation/d/1HgKTPPPUA7hyLGmAwSAeAe4Nr9FhS0J9vmu8pdH8lQM/edit?usp=sharing){:target="_blank" rel="noopener"}\]\
Tackled reconstruction of music listened by a subject based on their fMRI scans. Using [Nakai et al's dataset](https://pubmed.ncbi.nlm.nih.gov/34917714/){:target="_blank" rel="noopener"} of 5 subjects' fMRI scans while listening to 540 music pieces. Modified Meta's [MusicGen](https://audiocraft.metademolab.com/musicgen.html){:target="_blank" rel="noopener"} model for music generation conditioned on fMRI scans using the Map Method. Experimented with EnCodec, Chromagram Tokenizer, and T5 encoders, achieving the best performance using the T5 encoder with total averaging (FAD: 8.41, KL: 2.42, MCD: 4.87). Identified the temporal lobe as crucial for music reconstruction, highlighting the importance of auditory processing, language comprehension, and multimodal integration in the neural representation of music.

**Multimodal Emotion-Cause Analysis in Conversations using in-context learning and instruction-tuned LLMs**  
*SemEval 2024 Workshop Task 3 Competition*\
\[[Paper](https://arxiv.org/abs/2403.04798){:target="_blank" rel="noopener"}\] \[[Code](https://github.com/CMOONCS/SemEval-2024_MultiModal_ECPE/tree/main){:target="_blank" rel="noopener"}\]\
Developed an efficient video captioning technique for conversational videos using GPT-4-Vision. Used Demonstration learning through retrieved examples for emotion recognition and cause prediction using GPT-3.5 for SemEval Task 3. Also implemented instruction-tuned Llama-2 model using QLoRA tecnique. Our approach won rank 4 in the competition. \
_(Paper Accepted!)_\
![Static Badge](https://img.shields.io/badge/--%23412991?logo=openai&label=openai)
![Static Badge](https://img.shields.io/badge/--green?label=%F0%9F%A6%9C%EF%B8%8Flangchain)
![Static Badge](https://img.shields.io/badge/--red?logo=pytorch&label=pytorch)
![Static Badge](https://img.shields.io/badge/--%230467DF?logo=meta&label=llama)
![Static Badge](https://img.shields.io/badge/--%23FFBE00?label=%F0%9F%A4%97accelerate)


**Multimodal Emotion-Cause Pair Extraction using Graph Neural Networks**  
*Bachelors Minor Thesis, 2023*\
\[[Thesis](https://drive.google.com/file/d/1PHWEezwM0vujDF8mSSSPtaIpPMI6GTC5/view?usp=sharing){:target="_blank" rel="noopener"}\] \[[Slides](https://docs.google.com/presentation/d/1aQwf8vZg3c26uXxFzovtNwA92x8kad-IrHTJ6gKgHsk/edit?usp=sharing){:target="_blank" rel="noopener"}\]\
Developed a graph neural network for emotion-cause pair extraction from multimodal conversational data. Utilized CLIP,
BERT, and HTS-AT audio encoder for diverse modality features. Explored multimodal fusion in transformers. Modeled
conversational structure with graph attention networks.\
![Static Badge](https://img.shields.io/badge/--red?logo=pytorch&label=pytorch)
![Static Badge](https://img.shields.io/badge/--%23FFBE00?logo=weightsandbiases&label=%20weights%26biases)
![Static Badge](https://img.shields.io/badge/transformers-5b5d5b?label=%F0%9F%A4%97)

**Real-time Indoor Video Dehazing using Knowledge Distillation**\
*Smart India Hackathon Grand Finale, 2023* \
\[[Slides](https://drive.google.com/file/d/1_YyKU8hJbUSRMd9U_3KBGM3byju15JR9/view?usp=sharing){:target="_blank" rel="noopener"}\] \[[Solution Proposal](https://drive.google.com/file/d/1aWfAYDyxl2WXu0YaAbVPJdc2giFlot6J/view?usp=sharing){:target="_blank" rel="noopener"}\]\
We proposed to modify MAPNet, a UNET-based dehazing network for outdoor environments by replacing some of the blocks with TAM-Net, a 2D convolutional variant for videos. We experimented with distillation by creating a smaller student network for dehazing. During the hackathon, we experimented with Dark Channel Prior and Boundary Contrainst Regularization approaches for benchmarking. \
![Static Badge](https://img.shields.io/badge/--red?logo=pytorch&label=pytorch){:target="_blank" rel="noopener"}
![Static Badge](https://img.shields.io/badge/_-%235C3EE8?logo=opencv&label=opencv){:target="_blank" rel="noopener"}

**Self-Supervised Learning for Free-Viewing Scanpaths**\
*DAAD-WISE Research Project at TU Munich, 2023*\
\[[Slides](https://docs.google.com/presentation/d/17F_fqesKFqedVg6sIdlgmOhkPmw0T2909jU3WfDWfX0/edit?usp=sharing){:target="_blank" rel="noopener"}\] \[[Code](https://github.com/m-abbas-ansari/SSSL){:target="_blank" rel="noopener"}\]\
Eye movements can serve as a proxy for extracting neurological states of a subject. Our goal was to improve classifcation of a subject's cognitive characteristics based on their free-viewing scanpaths on images. We experimented with using a non-contrastive self-supervised learning technique based on BarlowTwins where we implemented novel scanpath distortion techniques to create multiple views of scanpaths. A combined  dataset was created using multiple publicly availble free-viewing scanpath datasets. Experiments demonstrated improvements in the downstream task of Autism detection.\
![Static Badge](https://img.shields.io/badge/--red?logo=pytorch&label=pytorch)
![Static Badge](https://img.shields.io/badge/--%23FFBE00?logo=weightsandbiases&label=%20weights%26biases)



**Super-Resolution of Digital Elevation Models (DEM)**\
*Smart India Hackathon Grand Finale, 2022 & IEEE IGARSS, 2023*\
\[[Slides](https://docs.google.com/presentation/d/13GKR8H8AjNDSijtup7leRnFHKwMQXmlF_HYQ5mBuW0I/edit?usp=sharing){:target="_blank" rel="noopener"}\] \[[Code](https://github.com/m-abbas-ansari/SuperResolution-DEMs){:target="_blank" rel="noopener"}\] \[[Paper](https://ieeexplore.ieee.org/abstract/document/10283196){:target="_blank" rel="noopener"}\]\
Led a team in developing a U-Net based convolutional network with attention for DEM super-resolution in ISRO’s Smart India Hackathon. DEMs collected from USGS LiDAR and SRTM, NASA ASTER and ISRO CartoSAT were used to curate the training set. Our team proposed MASTER GAN architecture achieving state-of-the-art results (PSNR 31.024, SSIM 0.908){:target="_blank" rel="noopener"} which got published at IEEE IGARSS 2023 conference.\
![Static Badge](https://img.shields.io/badge/--red?logo=pytorch&label=pytorch)
![Static Badge](https://img.shields.io/badge/_-%235C3EE8?logo=opencv&label=opencv)
![Static Badge](https://img.shields.io/badge/--%23FFBE00?logo=weightsandbiases&label=%20weights%26biases)

**Improved Visual Attention Classification for Autism Spectrum Disorder through Time-Dependent
Representations.**\
*Research Internship Project at IIIT Allahabad, 2022*\
\[[Slides](https://docs.google.com/presentation/d/1yQrqDBjhvNhPT4DhqcKf0RKzAifh-x9uRPPa5BwlsEg/edit?usp=sharing){:target="_blank" rel="noopener"}\] \[[Code](https://github.com/m-abbas-ansari/ASD-Classification){:target="_blank" rel="noopener"}\] \
Trained a deep learning network on Saliency4ASD dataset using ResNet-50 and LSTM using novel time-dependent representations. Encoded embeddings with duration via new techniques such as time-masking and joint embedding. Demonstrated improvements with incorporation of duration as a feature for ASD classification.\
![Static Badge](https://img.shields.io/badge/--red?logo=pytorch&label=pytorch)
![Static Badge](https://img.shields.io/badge/--%23FFBE00?logo=weightsandbiases&label=%20weights%26biases)

**Text Localization using Efficient Attention**\
*Research Project under Mentorship of [Mr Hitesh Hinduja](https://hitesh-hinduja.mystrikingly.com/){:target="_blank" rel="noopener"}*, 2021-23\
\[[Code](https://github.com/m-abbas-ansari/AttentionText){:target="_blank" rel="noopener"}\] \[[Paper](https://www.iosrjournals.org/iosr-jce/papers/Vol25-issue1/Ser-1/E2501013749.pdf){:target="_blank" rel="noopener"}\] \
Modified Mask R-CNN Architecture of Detectron2 library with efficient attention for improved text localization accuracy on SynthText dataset.\
![Static Badge](https://img.shields.io/badge/--red?logo=pytorch&label=pytorch)

**Robust Face Recognition Security System**\
*HackJMI Hackathon Project, 2021*\
\[[Code](https://github.com/m-abbas-ansari/HackJMI2-CheemsGamg){:target="_blank" rel="noopener"}\] \
Developed a robust face recognition security system using MTCNN, VGGFace, and inception-resnet siamese network capable of detecting spoof faces. A website with flask backend was created as MVP which won runner-up position at the hackathon.\
![Static Badge](https://img.shields.io/badge/_-%23FF6F00?logo=tensorflow&label=tensorflow)
![Static Badge](https://img.shields.io/badge/_-%23D00000?logo=keras&label=keras)
![Static Badge](https://img.shields.io/badge/_-%235C3EE8?logo=opencv&label=opencv)
![Static Badge](https://img.shields.io/badge/_-%23000000?logo=flask&label=flask)

**Novel Bible Verse Generator**\
*First Deep Learning Project, 2021*\
\[[Notebook](https://github.com/m-abbas-ansari/Machine-Learning-And-Data-Science/blob/main/pulp_fiction_quote_generation.ipynb){:target="_blank" rel="noopener"}\] \[[Example](https://www.linkedin.com/feed/update/urn:li:activity:6812461393271435264/){:target="_blank" rel="noopener"}\] \
Trained a character-level neural language model on Bible (KJV) using LSTM. Built a loop to generate 1000 characters from the seed text which was the fake Bible verse quote from pulp fiction (1994)\
![Static Badge](https://img.shields.io/badge/_-%23D00000?logo=keras&label=keras)
